{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTIDIONAL FREQUENCY DISTRIBUTION\n",
    "\n",
    "\n",
    "Let's look at how some specific words are used over time. In order to do this, NLTK's Conditional Frequency Distribution will be used. A conditional frequency distribution is a collection of frequency distributions, each one for a different \"condition\".\n",
    "This code checks if the words start with either of the \"targets\" (words we want to see over the time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import inflection as inf\n",
    "from inflection import singularize\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(r'\\Users\\claud\\OneDrive\\Desktop\\abstract_csv\\ahmfinal.csv')\n",
    "df= pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advanced</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['2012 mar 22708076 fabrication of a hybrid mi...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['2012 jul 23061030 dual imaging enabled cance...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['2013 jan 23184367 eradicating antibiotic res...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['2013 jan 23184402 sirna transfection with ca...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['2013 jan 23184404 towards smart tattoos impl...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>['2020 dec 13 33314663 an alternating irradiat...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>['2020 dec 16 33326185 which is better for nan...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>['2020 dec 18 33336546 nanocellulose reinforce...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>['2020 sep 33448676 an ultrasound excitable ag...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>['2020 sep 33448702 a ph sensitive self assemb...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2316 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               advanced  date\n",
       "0     ['2012 mar 22708076 fabrication of a hybrid mi...  2012\n",
       "1     ['2012 jul 23061030 dual imaging enabled cance...  2012\n",
       "2     ['2013 jan 23184367 eradicating antibiotic res...  2013\n",
       "3     ['2013 jan 23184402 sirna transfection with ca...  2013\n",
       "4     ['2013 jan 23184404 towards smart tattoos impl...  2013\n",
       "...                                                 ...   ...\n",
       "2311  ['2020 dec 13 33314663 an alternating irradiat...  2020\n",
       "2312  ['2020 dec 16 33326185 which is better for nan...  2020\n",
       "2313  ['2020 dec 18 33336546 nanocellulose reinforce...  2020\n",
       "2314  ['2020 sep 33448676 an ultrasound excitable ag...  2020\n",
       "2315  ['2020 sep 33448702 a ph sensitive self assemb...  2020\n",
       "\n",
       "[2316 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = [x[2:6] for x in df['advanced']] #create a dataframe for the date\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have the dates in our dataframe, we clean the data by deleting all digits and puntuaction signs. \n",
    "#words with less than 3 characters will also be removed\n",
    "def preprocess(text):\n",
    "    text = re.sub('[^a-zA-Z ]','' , text) #remove puntuaction signs and digits \n",
    "    text = re.sub(r'\\b\\w{1,3}\\b','' , text) #remove all words with less than 4 letters\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['advanced'] = df['advanced'].apply(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the list of stopwords\n",
    "stop = stopwords.words('english')\n",
    "newstopwords = [\"report\",\"summarize\",\"review\",\"demonstated\",\"significantly\",\"efficiently\",\"appeared\",\"loosening\", \"['\",\"using\",\"based\",\".\",\"statement\",\"significance\",\"result\",\"results\",\"used\",\"application \",\"release\",\"effect\",\"study\",\"significant\",\"showed\",\"p\",\"also\",\"model\",\"models\"]\n",
    "stop.extend(newstopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advanced</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fabrication hybrid microfluidic system incorpo...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dual imaging enabled cancer targeting nanopart...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eradicating antibiotic resistant biofilm silve...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sirna transfection calcium phosphate nanoparti...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toward smart tattoo implantable biosensor cont...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>alternating irradiation strategy driven combin...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>better nanomedicine nanocatalyst single atom c...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>nanocellulose reinforced hydroxyapatite nanobe...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>ultrasound excitable aggregation induced emiss...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>sensitive self assembled carrier free nanopart...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2316 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               advanced  date\n",
       "0     fabrication hybrid microfluidic system incorpo...  2012\n",
       "1     dual imaging enabled cancer targeting nanopart...  2012\n",
       "2     eradicating antibiotic resistant biofilm silve...  2013\n",
       "3     sirna transfection calcium phosphate nanoparti...  2013\n",
       "4     toward smart tattoo implantable biosensor cont...  2013\n",
       "...                                                 ...   ...\n",
       "2311  alternating irradiation strategy driven combin...  2020\n",
       "2312  better nanomedicine nanocatalyst single atom c...  2020\n",
       "2313  nanocellulose reinforced hydroxyapatite nanobe...  2020\n",
       "2314  ultrasound excitable aggregation induced emiss...  2020\n",
       "2315  sensitive self assembled carrier free nanopart...  2020\n",
       "\n",
       "[2316 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['advanced'] = df['advanced'].apply(lambda x: ' '.join([inf.singularize(word) for word in x.split() if word not in (stop)]))\n",
    "df #check the clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           fabrication\n",
       "1                hybrid\n",
       "2          microfluidic\n",
       "3                system\n",
       "4         incorporating\n",
       "              ...      \n",
       "247220       multimodal\n",
       "247221          imaging\n",
       "247222           guided\n",
       "247223       synergetic\n",
       "247224          therapy\n",
       "Length: 247225, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the data\n",
    "tokens = pd.Series(' '.join(df.advanced).split())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ConditionalFreqDist\n",
    "#calculate CFD\n",
    "cfd = nltk.ConditionalFreqDist((term, date) for term in ['silk'] for date in df.date[:] for w in tokens if w.startswith(term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2012  2013  2014  2015  2016  2017  2018  2019  2020 \n",
      "silk 18396 34602 44019 58254 65919 65043 76650 72270 72051 \n"
     ]
    }
   ],
   "source": [
    "#to see the results\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to plot the results\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count top 15 most commont words in the document\n",
    "wordcount = df.groupby(\"date\")[\"text\"].apply(lambda x: Counter(\" \".join(x).split()).most_common(15))\n",
    "wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will count the words of a specific word in the document using re, but without grouping it by year\n",
    "lista = df['advanced'].tolist()\n",
    "lista = [''.join(lista[:])]\n",
    "string = \" \".join(str(x) for x in lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = sum(1 for match in re.finditer(r\"\\bsilk\\b\", string)) #to count a specific word\n",
    "count #the difference is huge "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
